\documentclass[unicode,12pt,aspectratio=169,dvipdfmx]{beamer}
\usepackage{bxdpx-beamer}
\usetheme[progressbar=frametitle]{metropolis}
\renewcommand{\kanjifamilydefault}{\gtdefault}
\usepackage{bm}
\usepackage{tikz, pgfgantt}
\usetikzlibrary{arrows.meta, positioning, decorations.pathreplacing, calc}

\RequirePackage{tabularx} % 表の幅を指定するためのパッケージ
% \RequirePackage[bibstyle=bibliography,sorting=none,date=year,isbn=false,doi,giveninits,urldate=iso,seconds]{biblatex} % biblatexを使用するためのパッケージ
\usepackage[
  backend=biber,     % 参考文献処理にBiberを使うことを明記（強く推奨）
  style=numeric,       % 番号形式のスタイル [1], [2] ...
  sorting=none,        % 引用順に並べる
  date=year,
  isbn=false,
  doi=true,            % doiを表示する場合はtrue
  giveninits,
  urldate=iso,
  seconds
]{biblatex}
\addbibresource{references.bib}



\title{\textbf{自立生活支援のための音響イベント検出の連合学習}}
\author{竹本志恩}
\date{\today}

\begin{document}

% Slide 1: Title
\begin{frame}
  \titlepage
\end{frame}

% Section 1: 研究テーマ
\section{研究テーマ}
\begin{frame}{テーマ概要}
    \begin{itemize}
        \item 少子高齢化により医療と介護の負担は増大
        \item \textbf{AAL (Ambient Assisted Living)} \cite{blackman2016ambient,stodczyk2020ambient}
        \begin{itemize}
            \item 情報技術で自立的な生活を支援し, 在宅介護で問題解決を目指す
        \end{itemize}
            \item \textbf{従来手法の課題}
        \begin{itemize}
            \item 主にカメラを用いるが, 高価でプライバシー受容性に難点
            \item ウェアラブルは充電や装着し忘れ, 侵襲性の問題
        \end{itemize}
        \item \textbf{音響イベント検出（Sound Event Detection, SED）で解決}
        \begin{itemize}
            \item 音による行動認識で, 異常検知や健康状態の把握を目指す
            \item カメラより安価で, 音特有の異常兆候を検出
            \item 機械学習で多様な環境や対象に柔軟に対応
            \item SEDで「いつ, どんな行動があったか」を理解し, 説明性のある異常検知モデル構築を目指す
        \end{itemize}
    \end{itemize}
\end{frame}


\begin{frame}{音響イベント検出とは}
    \begin{itemize}
        \item 与えられた音から，イベントを検出するタスク
        \item イベントの開始と終了，ラベルを予測
        \item 音響シーン分類との違い
        \begin{itemize}
            \item 音響シーン分類は一定時間の音のラベルのみ予測
            \item SEDは音の発生時間や持続時間も考慮
        \end{itemize}
        \item AcousticとSoundの違いは未調査
    \end{itemize}
\end{frame}


\begin{frame}{図}
% 音響シーン分類と音響イベント検出の違いを示す図
\begin{center}
    \begin{tikzpicture}[
        scale=0.9, transform shape,
        font=\sffamily\small, % フォント設定
        % 各ブロックのスタイル定義
        event/.style={rectangle, draw, thick, fill=cyan!30, minimum height=0.7cm, text centered, font=\sffamily\small},
        scene/.style={rectangle, draw, thick, fill=orange!30, minimum height=0.7cm, text centered, font=\sffamily\small}
    ]

    % --- 音響シーン分類 ---
    \node[anchor=west, font=\sffamily\bfseries] at (0, 2.5) {音響シーン分類 (Acoustic Scene Classification)};
    % タイムラインの描画
    \draw[-{Stealth}] (0, 1.5) -- (10.5, 1.5) node[right] {時間};
    \foreach \x in {0,2,...,10} {
        \draw (\x, 1.6) -- (\x, 1.4) node[below] {\x s};
    }
    % シーン全体のブロック
    \draw[scene] (0, 0) rectangle (10, 0.7) node[pos=.5] {「公園」の音};
    % 説明用の括弧
    \draw[decorate, decoration={brace, amplitude=5pt, raise=2pt}] (0, -0.1) -- (10, -0.1) 
        node[midway, below=8pt] {音声全体に単一のラベルを予測};

    % --- 音響イベント検出 ---
    \begin{scope}[yshift=-4cm]
        \node[anchor=west, font=\sffamily\bfseries] at (0, 2.5) {音響イベント検出 (Acoustic Event Detection)};
        % タイムラインの描画
        \draw[-{Stealth}] (0, 1.5) -- (10.5, 1.5) node[right] {時間};
        \foreach \x in {0,2,...,10} {
            \draw (\x, 1.6) -- (\x, 1.4) node[below] {\x s};
        }
        % 各イベントのブロック
        \draw[event] (1, 0) rectangle (3, 0.7) node[pos=.5] {犬の鳴き声};
        \draw[event] (4, 0) rectangle (7, 0.7) node[pos=.5] {鳥のさえずり};
        \draw[event] (7, 0) rectangle (9, 0.7) node[pos=.5] {足音};
        % 説明用の括弧
        \draw[decorate, decoration={brace, amplitude=5pt, raise=2pt}] (1, -0.1) -- (9, -0.1) 
            node[midway, below=8pt] {個別のイベントとその時間を予測};
    \end{scope}

    \end{tikzpicture}
\end{center}
\end{frame}



% Section 2: 課題と問い
\section{研究課題}
\begin{frame}{テーマで取り組む課題}
    \begin{itemize}
        \item \textbf{総合的な課題: 連合学習によるプライバシー問題の解決}
        \begin{itemize}
            \item AALはプライバシー性の高いデータを扱う
            \item 従来の中央集権的な機械学習はプライバシーに課題
            \item 本研究では, この課題を\textbf{連合学習(Federated Learning, FL)}で解決
            \item エッジデバイスの先行研究もある\cite{alsina2017homesound}が, より柔軟なFLに着目
        \end{itemize}
        \item \textbf{本研究における問い}
        \begin{enumerate}
            \item 中央集権的手法と比較し, 連合学習でどれだけ精度を維持できるか？
            \item どの連合学習アルゴリズムが家庭内環境に対して適切か？
        \end{enumerate}
        \item \textbf{展望}
        \begin{itemize}
            \item SEDを手がかりに異常検知
        \end{itemize}
    \end{itemize}
\end{frame}

% Section 3: 実験計画
\section{実験計画}
\begin{frame}{実験評価計画 (1/2)}
    \begin{itemize}
        \item 7月
        \begin{itemize}
            \item 研究計画書を作成
            \item 各評価指標の意味を理解
            \item 具体的な目標精度を決定
        \end{itemize}
        \item 7-8月
        \begin{itemize}
            \item 適切なモデルアーキテクチャの比較・検討 \cite{li2022hybrid,schmid2024multi}
            \begin{itemize}
                \item 事前学習済みモデルの比較
                \item 適切なCNN，RNNの構成を模索
                \item 事前学習済みモデル+CNN+RNNの構成を模索
            \end{itemize}
            \item 適切な学習戦略を決定
            \begin{itemize}              
                \item 前処理/後処理の方法，アンサンブルの有無など
                \item 特に半教師あり学習の手法を検討 (\textbf{Mean-Teacher}か\textbf{FixMatch}を想定)
                \item DCASE 2024を参照
            \end{itemize}
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{実験評価計画 (2/2)}
    \begin{itemize}
        \item 9月
        \begin{itemize}
            \item 前処理, 後処理, モデル構成要素の精度への影響を調査
        \end{itemize}
        \item 9-10月
        \begin{itemize}
            \item 連合学習モデルの精度を従来手法と比較
            \begin{itemize}
                \item ベースライン: FedAVG \cite{mcmahan2017communication}
                \item 比較対象: FedProx \cite{li2020federated}, SCAFFOLD \cite{karimireddy2020scaffold}などを予定
                \item 連合学習のハイパーパラメータを調整
            \end{itemize}
        \end{itemize}
        \item 11月
        \begin{itemize}
            \item 考察
        \end{itemize}
    \end{itemize}
\end{frame}

% Section 4: 評価方法
\section{評価方法}
\begin{frame}{評価方法}
    \begin{itemize}
        \item モデル共通の前提
        \begin{itemize}
            \item 基本モデル: DCASE 2024のベースライン
            \item データセット: DESED，MAESTRO
        \end{itemize}

        \item \textbf{モデルの比較対象}
        \begin{itemize}
            \item ベースラインやSOTA(State-of-the-Art)と比較
        \end{itemize}
        \item \textbf{評価指標}
        \begin{itemize}
            \item DCASE 2024のSupplementary metricsを参照
            \item 各種\textbf{F1スコア}+\textbf{PSDS (Polyphonic Sound Detection Score)} 1, 2を使用
        \end{itemize}
        \item \textbf{精度の基準}
        \begin{itemize}
            \item 連合学習を適用した場合の精度を中央集権的な手法と比較
            \item 従来手法から少し劣る精度が目標
        \end{itemize}
    \end{itemize}
\end{frame}

\section{進捗}
\begin{frame}{進捗}
    \begin{itemize}
        \item $\checkmark$各種サーベイを実施
        \begin{itemize}
            \item 技術的な理解はこれから
            \item 連合学習/音響イベント検出/半教師あり学習の調査
            \item 自立生活支援の研究目的を理解
            \item DCASE task4 2018-2024の大まかな内容を把握
        \end{itemize}    
        \item 実験評価計画タスク    
        \begin{itemize}
            \item 研究計画書: ほぼ完了
            \item 各評価指標，目標精度: 指標は把握
            \item モデルアーキテクチャ: 使用するモデルは概ね把握
            \item 学習戦略を決定: 半教師あり学習手法は把握，全体は論文を参考に検討中
            \item 精度影響の調査: 未着手
            \item 連合学習: FedAVG，FedProxは追試済み，他は未調査
        \end{itemize}    
    \end{itemize}
\end{frame}

% Section 5: 先行研究
\begin{frame}[allowframebreaks]
% 必要な先行研究を抽出して載せる + bibtexで[1]とか参照
% https://scrapbox.io/main-custard/%E5%8D%92%E8%AB%96%E3%81%AE%E4%B8%BB%E8%A6%81%E3%81%AA%E5%85%88%E8%A1%8C%E7%A0%94%E7%A9%B6をかく
% \addcontentsline{toc}{chapter}{参考文献}
\printbibliography
\end{frame}
\end{document}